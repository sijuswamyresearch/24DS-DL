[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Basics of Artificial Neural Network",
    "section": "",
    "text": "1.1 Introduction to Artificial Neural Networks (ANNs)\nMachine learning has undeniably become a prominent and dynamic field, with its vast array of algorithms sometimes making it challenging to discern key concepts. To gain a clearer understanding, it is valuable to explore various machine learning algorithms in greater detail, focusing not only on their theoretical foundations but also on their step-by-step implementation.\nIn brief, machine learning is defined as a field that enables computers to learn from data without explicit programming (Arthur Samuel, 1959). It involves the development of algorithms capable of recognizing patterns in data and making decisions based on statistical analysis, probability theory, combinatorics, and optimization techniques.\nThis discussion begins with an exploration of perceptrons and ADALINE (Adaptive Linear Neuron), which are part of single-layer neural networks. The perceptron is the first algorithmically defined learning algorithm and serves as an intuitive, easy-to-implement introduction to modern machine learning algorithms, particularly artificial neural networks (or “deep learning”). ADALINE, an improvement on the perceptron, provides an excellent opportunity to understand gradient descent, a widely-used optimization method in machine learning.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "intro.html#key-ideas",
    "href": "intro.html#key-ideas",
    "title": "1  Basics of Artificial Neural Network",
    "section": "1.3 Key Ideas",
    "text": "1.3 Key Ideas\n\nPerceptron: A linear classifier with a simple learning rule based on weight updates.\nMultilayer Perceptron (MLP): Extends the perceptron by introducing hidden layers and non-linear activation functions.\nSigmoid Neurons: Replace the step activation function with a sigmoid function for smoother learning and compatibility with gradient-based optimization.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "intro.html#mathematical-models",
    "href": "intro.html#mathematical-models",
    "title": "1  Basics of Artificial Neural Network",
    "section": "1.4 Mathematical Models",
    "text": "1.4 Mathematical Models\n\n1.4.1 Perceptron Model\n\n\n\n\n\ngraph TD\n    X1(Input X1) --&gt; W1(Weight W1)\n    X2(Input X2) --&gt; W2(Weight W2)\n    Xn(Input Xn) --&gt; Wn(Weight Wn)\n    W1 --&gt; SUM[Summation Σ]\n    W2 --&gt; SUM\n    Wn --&gt; SUM\n    B(Bias) --&gt; SUM\n    SUM --&gt; ACT[Activation Function]\n    ACT --&gt; Y(Output Y)\n    \n    style SUM fill:#f9f,stroke:#333,stroke-width:2px\n    style ACT fill:#bbf,stroke:#333,stroke-width:2px\n    style Y fill:#bfb,stroke:#333,stroke-width:2px\n    classDef input fill:#ff9,stroke:#333,stroke-width:2px;\n    classDef weight fill:#9cf,stroke:#333,stroke-width:2px;\n\n    class X1,X2,Xn input;\n    class W1,W2,Wn weight;\n\n\n\n\n\n\nThe perceptron computes a weighted sum of inputs and applies a step function for classification: \\[\nz = \\sum_{i=1}^n w_i x_i + b\n\\] \\[\n\\hat{y} = \\begin{cases}\n      1 & \\text{if } z &gt; 0 \\\\\n      0 & \\text{otherwise}\n   \\end{cases}\n\\]\n\n\n1.4.2 Perceptron Learning Rule\nWeights are updated iteratively based on the error: \\[\nw_i \\gets w_i + \\eta (y - \\hat{y}) x_i\n\\] where \\(\\eta\\) is the learning rate.\n\n\n1.4.3 Simulating OR gate using Perceptron\n\n\n\n\n\n\n\nperceptron\n\n\n\ninput1\n\nx1\n\n\n\nweight1\n\nw1\n\n\n\ninput1-&gt;weight1\n\n\nw1\n\n\n\ninput2\n\nx2\n\n\n\nweight2\n\nw2\n\n\n\ninput2-&gt;weight2\n\n\nw2\n\n\n\nbias\n\nBias (b)\n\n\n\nweighted_sum\n\nw1 * x1 + w2 * x2 + b\n\n\n\nbias-&gt;weighted_sum\n\n\n + b\n\n\n\nweight1-&gt;weighted_sum\n\n\n* x1\n\n\n\nweight2-&gt;weighted_sum\n\n\n* x2\n\n\n\nactivation\n\nActivation Step Function: f(x) = 1 if x &gt;= 0 else 0\n\n\n\nweighted_sum-&gt;activation\n\n\npass to\n\n\n\noutput\n\ny (Output)\n\n\n\nactivation-&gt;output\n\n\nstep function\n\n\n\noutput-&gt;output\n\n\ny\n\n\n\n\n\n\n\n\nThe following python code will simulate the OR gate using the logic of perceptron.\n\nimport numpy as np\n\n# Step function (activation function)\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron training algorithm\ndef perceptron(X, y, learning_rate=0.1, epochs=10):\n    # Initialize weights and bias\n    weights = np.zeros(X.shape[1])\n    bias = 0\n    \n    # Training process\n    for epoch in range(epochs):\n        total_error = 0\n        for i in range(len(X)):\n            # Calculate weighted sum (z)\n            z = np.dot(X[i], weights) + bias\n            # Apply step function to get prediction\n            prediction = step_function(z)\n            \n            # Calculate error\n            error = y[i] - prediction\n            total_error += abs(error)\n            \n            # Update weights and bias based on the error\n            weights += learning_rate * error * X[i]\n            bias += learning_rate * error\n        \n        # Optionally, print the error for each epoch\n        print(f'Epoch {epoch + 1}: Total Error = {total_error}')\n    \n    return weights, bias\n\n# Perceptron test function\ndef predict(X, weights, bias):\n    predictions = []\n    for i in range(len(X)):\n        z = np.dot(X[i], weights) + bias\n        prediction = step_function(z)\n        predictions.append(prediction)\n    return predictions\n\n# OR Gate Inputs and Outputs\n# Input X: [A, B] where A and B are the inputs\n# Output y: The corresponding OR operation output\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([0, 1, 1, 1])  # OR gate outputs\n\n# Train the perceptron\nweights, bias = perceptron(X, y, learning_rate=0.1, epochs=10)\n\n# Test the perceptron\npredictions = predict(X, weights, bias)\n\n# Print predictions\nprint(\"\\nPredictions:\")\nfor i in range(len(X)):\n    print(f'Input: {X[i]}, Predicted Output: {predictions[i]}')\n\nEpoch 1: Total Error = 2\nEpoch 2: Total Error = 2\nEpoch 3: Total Error = 1\nEpoch 4: Total Error = 0\nEpoch 5: Total Error = 0\nEpoch 6: Total Error = 0\nEpoch 7: Total Error = 0\nEpoch 8: Total Error = 0\nEpoch 9: Total Error = 0\nEpoch 10: Total Error = 0\n\nPredictions:\nInput: [0 0], Predicted Output: 0\nInput: [0 1], Predicted Output: 1\nInput: [1 0], Predicted Output: 1\nInput: [1 1], Predicted Output: 1\n\n\n\n\n1.4.4 Simulating AND gate using a perceptron\nThe perceptron model for an AND gate is shown below.\n\n\n\n\n\n\n\nperceptron\n\n\n\ninput1\n\nx1\n\n\n\nweight1\n\nw1\n\n\n\ninput1-&gt;weight1\n\n\nw1\n\n\n\ninput2\n\nx2\n\n\n\nweight2\n\nw2\n\n\n\ninput2-&gt;weight2\n\n\nw2\n\n\n\nbias\n\nBias (b)\n\n\n\nweighted_sum\n\nw1 * x1 + w2 * x2 + b\n\n\n\nbias-&gt;weighted_sum\n\n\n + b\n\n\n\nweight1-&gt;weighted_sum\n\n\n* x1\n\n\n\nweight2-&gt;weighted_sum\n\n\n* x2\n\n\n\nactivation\n\nActivation Step Function: f(x) = 1 if x &gt;= 0 else 0\n\n\n\nweighted_sum-&gt;activation\n\n\npass to\n\n\n\noutput\n\ny (Output)\n\n\n\nactivation-&gt;output\n\n\nstep function\n\n\n\noutput-&gt;output\n\n\ny\n\n\n\n\n\n\n\n\nThe python code for simulating the AND gate using the perceptron is shown below.\n\nimport numpy as np\n\n# Step function (activation function)\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron training algorithm\ndef perceptron(X, y, learning_rate=0.1, epochs=10):\n    # Initialize weights and bias\n    weights = np.zeros(X.shape[1])\n    bias = 0\n    \n    # Training process\n    for epoch in range(epochs):\n        total_error = 0\n        for i in range(len(X)):\n            # Calculate weighted sum (z)\n            z = np.dot(X[i], weights) + bias\n            # Apply step function to get prediction\n            prediction = step_function(z)\n            \n            # Calculate error\n            error = y[i] - prediction\n            total_error += abs(error)\n            \n            # Update weights and bias based on the error\n            weights += learning_rate * error * X[i]\n            bias += learning_rate * error\n        \n        # Optionally, print the error for each epoch\n        print(f'Epoch {epoch + 1}: Total Error = {total_error}')\n    \n    return weights, bias\n\n# Perceptron test function\ndef predict(X, weights, bias):\n    predictions = []\n    for i in range(len(X)):\n        z = np.dot(X[i], weights) + bias\n        prediction = step_function(z)\n        predictions.append(prediction)\n    return predictions\n\n# OR Gate Inputs and Outputs\n# Input X: [A, B] where A and B are the inputs\n# Output y: The corresponding OR operation output\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([0, 1, 1, 1])  # OR gate outputs\n\n# Train the perceptron\nweights, bias = perceptron(X, y, learning_rate=0.1, epochs=10)\n\n# Test the perceptron\npredictions = predict(X, weights, bias)\n\n# Print predictions\nprint(\"\\nPredictions:\")\nfor i in range(len(X)):\n    print(f'Input: {X[i]}, Predicted Output: {predictions[i]}')\n\nEpoch 1: Total Error = 2\nEpoch 2: Total Error = 2\nEpoch 3: Total Error = 1\nEpoch 4: Total Error = 0\nEpoch 5: Total Error = 0\nEpoch 6: Total Error = 0\nEpoch 7: Total Error = 0\nEpoch 8: Total Error = 0\nEpoch 9: Total Error = 0\nEpoch 10: Total Error = 0\n\nPredictions:\nInput: [0 0], Predicted Output: 0\nInput: [0 1], Predicted Output: 1\nInput: [1 0], Predicted Output: 1\nInput: [1 1], Predicted Output: 1\n\n\n\n\n1.4.5 Simulating NOR gate using the Perceptron\nHere is the Python code to simulate a perceptron for a NOR gate. The NOR gate is the negation of the OR gate, so it outputs 1 only when both inputs are 0.\n\nimport numpy as np\n\n# Define the step function\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron class to simulate the NOR gate\nclass Perceptron:\n    def __init__(self, input_size, learning_rate=0.1):\n        # Initialize weights and bias to zero\n        self.weights = np.zeros(input_size)\n        self.bias = 0\n        self.learning_rate = learning_rate\n\n    def predict(self, inputs):\n        # Calculate the weighted sum\n        weighted_sum = np.dot(inputs, self.weights) + self.bias\n        # Apply the step activation function\n        return step_function(weighted_sum)\n\n    def train(self, inputs, targets, epochs=10):\n        # Train the perceptron using the input-output pairs\n        for epoch in range(epochs):\n            for i in range(len(inputs)):\n                input_data = inputs[i]\n                target = targets[i]\n                # Compute the prediction\n                prediction = self.predict(input_data)\n                # Calculate the error\n                error = target - prediction\n                # Update the weights and bias using the perceptron learning rule\n                self.weights += self.learning_rate * error * input_data\n                self.bias += self.learning_rate * error\n\n# Define the input-output pairs for a NOR gate\ninputs = np.array([\n    [0, 0],  # Input: (0, 0)\n    [0, 1],  # Input: (0, 1)\n    [1, 0],  # Input: (1, 0)\n    [1, 1],  # Input: (1, 1)\n])\n\n# Output of NOR gate\ntargets = np.array([1, 0, 0, 0])\n\n# Create and train the perceptron\nperceptron = Perceptron(input_size=2)\nperceptron.train(inputs, targets, epochs=10)\n\n# Test the trained perceptron on the inputs\nprint(\"Trained weights:\", perceptron.weights)\nprint(\"Trained bias:\", perceptron.bias)\n\n# Test the perceptron for all input combinations\nfor input_data in inputs:\n    prediction = perceptron.predict(input_data)\n    print(f\"Input: {input_data}, Prediction: {prediction}\")\n\nTrained weights: [-0.1 -0.1]\nTrained bias: 0.0\nInput: [0 0], Prediction: 1\nInput: [0 1], Prediction: 0\nInput: [1 0], Prediction: 0\nInput: [1 1], Prediction: 0\n\n\nThis code will train the perceptron to simulate the NOR gate and test it for all possible input combinations. The weights and bias will be adjusted during training to ensure the perceptron correctly implements the NOR gate behavior.\n\n\n1.4.6 Perceptron fails!\nwhether the perceptron win on XOR gate? No, the perceptron cannot learn the XOR gate. This is a well-known limitation of the perceptron model, and it’s related to the fact that the XOR function is non-linearly separable.\n\n\n\n\n\n\nPerceptron fails!\n\n\n\nA perceptron can only solve problems that are linearly separable, meaning that the classes (outputs) can be separated by a straight line (or a hyperplane in higher dimensions). The XOR gate outputs 1 when the inputs are (0, 1) or (1, 0), and outputs 0 when the inputs are (0, 0) or (1, 1).\nIf you try to plot these points, you’ll see that you can’t separate the positive examples (output 1) from the negative examples (output 0) with a single straight line.\n\n\n\n\n1.4.7 Perceptron neuron- the foundation of modern Machine Learning\nThe Perceptron model, introduced by Frank Rosenblatt in 1958, marked one of the earliest developments in artificial intelligence and neural networks. Initially conceived as a model for pattern recognition and early neural computation, the Perceptron was designed to simulate a biological neuron, learning to classify inputs into two categories through a simple linear decision boundary. Despite its early promise, the limitations of the basic Perceptron were exposed in the 1960s, particularly its inability to solve non-linearly separable problems, famously highlighted in Marvin Minsky and Seymour Papert’s book Perceptrons (1969). However, with the advent of more sophisticated algorithms and architectures, such as multi-layer perceptrons (MLPs) and the backpropagation algorithm in the 1980s, the Perceptron concept was revitalized. Today, it forms the foundational concept for deep learning models and modern neural networks, which are widely applied in various fields, including image and speech recognition, natural language processing, and autonomous systems, demonstrating its enduring relevance and adaptability in tackling complex, non-linear real-world problems.\n\n\n\n1.4.8 Introduction to the Sigmoid Activation Function\nThe sigmoid function, defined as\n\\[\n\\sigma(x) = \\frac{1}{1 + e^{-x}},\n\\]\nmaps any real-valued input to an output between 0 and 1, making it ideal for binary classification tasks. It has played a pivotal role in the development of neural networks, especially in overcoming the limitations of the step function used in early perceptrons.\n\n\n1.4.9 Historical Context\nIn the 1950s, Frank Rosenblatt’s perceptron used the step function, which works well for linearly separable problems but fails with more complex datasets, like the XOR problem. The introduction of the sigmoid activation function in the 1980s addressed this by enabling smooth decision boundaries and facilitating the backpropagation algorithm, allowing neural networks to learn from data effectively.\n\n\n1.4.10 Relevance to Modern Neural Networks\nThe sigmoid function’s differentiability makes it ideal for gradient-based optimization, which is essential for training deep neural networks. Its output is a probability, making it suitable for binary classification problems. Additionally, the derivative of the sigmoid is easy to compute:\n\\[\n\\sigma'(x) = \\sigma(x)(1 - \\sigma(x)),\n\\]\nwhich aids in backpropagation by allowing efficient weight updates. Despite some limitations, such as the vanishing gradient problem, the sigmoid function is widely used in the output layers of networks for tasks requiring probabilistic outputs.\n\n\n1.4.11 Applications\n\nBinary classification (e.g., logistic regression).\nOutput layer in neural networks for binary classification.\nProbabilistic models in machine learning and AI.\n\nWhile alternatives like ReLU are often used in deeper layers due to the vanishing gradient problem, sigmoid remains a powerful tool for probabilistic predictions.\n\n\n1.4.12 Sigmoid Neuron\nThe sigmoid neuron replaces the step function with the sigmoid function: \\[\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\] This allows for smooth gradients, enabling the use of backpropagation for training MLPs.\n\n\n\n\n\n\n\nNeuralNetwork\n\n\ncluster_input\n\nInput Layer\n\n\ncluster_output\n\nOutput Layer\n\n\ncluster_weights\n\nWeights\n\n\ncluster_neuron\n\nSigmoid Neuron\n\n\n\nX1\n\nx1\n\n\n\nW1\n\nw1\n\n\n\nX1-&gt;W1\n\n\n\n\n\nX2\n\nx2\n\n\n\nW2\n\nw2\n\n\n\nX2-&gt;W2\n\n\n\n\n\nXn\n\nxn\n\n\n\nWn\n\nwn\n\n\n\nXn-&gt;Wn\n\n\n\n\n\nSUM\n\nΣ = Σ(wi * xi) + b\n\n\n\nW1-&gt;SUM\n\n\n\n\n\nW2-&gt;SUM\n\n\n\n\n\nWn-&gt;SUM\n\n\n\n\n\nSIGMOID\n\nσ(z) = 1 / (1 + exp(-z))\n\n\n\nSUM-&gt;SIGMOID\n\n\n\n\n\nY\n\ny\n\n\n\nSIGMOID-&gt;Y\n\n\n\n\n\nB\n\nb (Bias)\n\n\n\nB-&gt;SUM\n\n\n\n\n\n\n\n\n\n\nFollowing python code demonstrate the effective use of the sigmoid activation function in the simulation of an AND gate.\n\nimport numpy as np\n\n# Sigmoid activation function\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# Derivative of sigmoid for gradient calculation\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\n# Define the training inputs and outputs (AND gate)\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([[0], [0], [0], [1]])  # Expected output for AND gate\n\n# Initialize weights and bias randomly\nweights = np.random.rand(2, 1)  # Random weights for 2 inputs\nbias = np.random.rand(1)  # Random bias\n\n# Learning rate\nlearning_rate = 0.1\n\n# Training the perceptron\nfor epoch in range(10000):  # Number of iterations\n    # Forward pass\n    weighted_sum = np.dot(X, weights) + bias\n    output = sigmoid(weighted_sum)\n\n    # Compute error\n    error = y - output\n    \n    # Backpropagation (Gradient Descent)\n    adjustment = error * sigmoid_derivative(output)\n    weights += np.dot(X.T, adjustment) * learning_rate\n    bias += np.sum(adjustment) * learning_rate\n\n    # Optional: Print the error at intervals\n    if epoch % 1000 == 0:\n        print(f\"Epoch {epoch}, Error: {np.mean(np.abs(error))}\")\n\n# Testing the perceptron\nprint(\"\\nFinal Output After Training:\")\nfor i in range(len(X)):\n    print(f\"Input: {X[i]} =&gt; Predicted Output: {round(output[i][0])}\")\n\nEpoch 0, Error: 0.539782555939579\nEpoch 1000, Error: 0.15752721009289428\nEpoch 2000, Error: 0.10904384979992113\nEpoch 3000, Error: 0.0870033499588651\nEpoch 4000, Error: 0.07402074220004146\nEpoch 5000, Error: 0.06530374971035827\nEpoch 6000, Error: 0.05896742743442092\nEpoch 7000, Error: 0.054109779416276246\nEpoch 8000, Error: 0.050240895600713084\nEpoch 9000, Error: 0.047069889543197296\n\nFinal Output After Training:\nInput: [0 0] =&gt; Predicted Output: 0\nInput: [0 1] =&gt; Predicted Output: 0\nInput: [1 0] =&gt; Predicted Output: 0\nInput: [1 1] =&gt; Predicted Output: 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "intro.html#important-theorems-and-results",
    "href": "intro.html#important-theorems-and-results",
    "title": "1  Basics of Artificial Neural Network",
    "section": "1.3 Important Theorems and Results",
    "text": "1.3 Important Theorems and Results\n\nPerceptron Convergence Theorem: If the data is linearly separable, the perceptron will converge to a solution in a finite number of steps.\nUniversal Approximation Theorem: An MLP with a single hidden layer and non-linear activation functions can approximate any continuous function.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "intro.html#examples",
    "href": "intro.html#examples",
    "title": "1  Basics of Artificial Neural Network",
    "section": "1.4 Examples",
    "text": "1.4 Examples\n\n1.4.1 Simple Example: Perceptron for AND Gate\n\nimport numpy as np\n\n# Inputs (x1, x2) and outputs (y)\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([0, 0, 0, 1])  # AND Gate Output\n\n# Initialize weights and bias\nweights = np.random.rand(2)\nbias = np.random.rand(1)\nlearning_rate = 0.1\n\n# Activation function\ndef step_function(z):\n    return 1 if z &gt; 0 else 0\n\n# Training loop\nfor epoch in range(10):  # 10 epochs\n    for i in range(len(X)):\n        z = np.dot(X[i], weights) + bias\n        y_pred = step_function(z)\n        error = y[i] - y_pred\n        weights += learning_rate * error * X[i]\n        bias += learning_rate * error\n\nprint(f\"Trained Weights: {weights}, Bias: {bias}\")\n\nTrained Weights: [0.16735027 0.15924483], Bias: [-0.2622418]\n\n\n\n\n\n\nRosenblatt, Frank. 1957. The Perceptron, a Perceiving and Recognizing Automaton Project Para. Cornell Aeronautical Laboratory.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "intro.html#introduction-to-artificial-neural-networks-anns",
    "href": "intro.html#introduction-to-artificial-neural-networks-anns",
    "title": "1  Basics of Artificial Neural Network",
    "section": "",
    "text": "1.1.1 Introduction\nArtificial Neural Networks (ANNs) are a class of computational models inspired by the biological neural networks in the human brain. These models have revolutionized numerous fields, including machine learning, computer vision, natural language processing, and data analytics, by mimicking the complex processing power of the human brain in a simplified computational framework. ANNs are at the core of deep learning algorithms, enabling machines to learn from vast amounts of data, recognize patterns, and make decisions with little to no human intervention.\nThe concept of ANNs can be traced back to the 1940s when pioneers like Warren McCulloch and Walter Pitts introduced the first simplified model of the neuron. In more intuitive terms, neurons can be understood as the subunits of a neural network in a biological brain. Here, the signals of variable magnitudes arrive at the dendrites. Those input signals are then accumulated in the cell body of the neuron, and if the accumulated signal exceeds a certain threshold, a output signal is generated that which will be passed on by the axon. This model, known as the McCulloch-Pitts neuron, was a logical abstraction that represented a binary decision-making process based on weighted inputs. However, it wasn’t until the 1980s, with the development of the backpropagation algorithm by Geoffrey Hinton and others, that ANNs began to demonstrate significant potential for learning complex patterns and tasks.\n\n\n\n\n\n\nKey Concepts in Artificial Neural Networks\n\n\n\n\nNeurons: The fundamental units in an ANN, inspired by biological neurons. Each neuron receives one or more inputs, processes them, and produces an output. The output is typically determined by applying an activation function to a weighted sum of the inputs.\nArchitecture: An ANN is composed of layers of neurons:\n\nInput Layer: The first layer that receives input data.\nHidden Layers: Intermediate layers where computations occur and complex features are learned.\nOutput Layer: The final layer that produces the output or prediction.\n\nThe number of layers and the number of neurons in each layer are important design considerations that influence the network’s ability to learn complex relationships.\nWeights and Biases: Each connection between neurons has an associated weight, which determines the importance of the input. Biases are added to the weighted sum to allow the network to better model the data and shift the activation function.\nActivation Function: The activation function introduces non-linearity into the model, enabling it to learn and represent complex patterns. Common activation functions include:\n\nSigmoid: A logistic function that outputs values between 0 and 1.\nTanh: A hyperbolic tangent function that outputs values between -1 and 1.\nReLU (Rectified Linear Unit): Outputs zero for negative inputs and the input value itself for positive inputs, helping mitigate the vanishing gradient problem in deep networks.\n\nLearning Process: Training an ANN involves adjusting the weights and biases through a process called optimization, typically using the gradient descent algorithm. During training, the network’s predictions are compared to the actual outcomes, and the difference, known as the loss or error, is minimized using optimization techniques.\nBackpropagation: This algorithm computes the gradient of the loss function with respect to each weight by applying the chain rule of calculus. This information is used to update the weights in a way that reduces the overall error, allowing the network to improve over time.\n\n\n\n\n\n1.1.2 Historical Development and Evolution\nThe origins of neural networks lie in the early 20th century, with key milestones such as the Perceptron (developed by Frank Rosenblatt in 1958) and the Backpropagation Algorithm (1986), which was a breakthrough in training multilayer networks. The development of the Deep Learning paradigm in the 2000s, fueled by advances in computing power, large datasets, and efficient algorithms, further accelerated the application of ANNs. Notable examples include Convolutional Neural Networks (CNNs) for image recognition and Recurrent Neural Networks (RNNs) for sequence modeling, such as speech and language processing.\n\n\n1.1.3 Modern Applications of Artificial Neural Networks\nIn recent years, the ability of ANNs to perform high-level tasks has grown substantially. Some of the transformative applications include:\n\nComputer Vision: ANNs are used in image classification, object detection, facial recognition, and medical image analysis.\nNatural Language Processing (NLP): ANNs, particularly transformer models, power state-of-the-art techniques in machine translation, sentiment analysis, and chatbots.\nRobotics and Autonomous Systems: Neural networks enable robots to perceive their environment and make real-time decisions.\nHealthcare: ANNs are applied in predictive analytics for disease diagnosis, treatment planning, and drug discovery.\nFinance: ANNs help in fraud detection, algorithmic trading, and customer behavior prediction.\n\n\n\n1.1.4 Challenges and Future Directions\nDespite their powerful capabilities, ANNs face several challenges:\n\nOverfitting: Neural networks can become too specialized to the training data, losing the ability to generalize to new, unseen data.\nInterpretability: The “black-box” nature of ANNs makes it difficult to understand how they arrive at specific decisions, which can be problematic in fields requiring explainability (e.g., healthcare, law).\nData and Computation: Training deep neural networks requires large amounts of labeled data and significant computational resources, which can be limiting in certain contexts.\n\nFuture research directions aim to address these challenges, including the development of more interpretable models, reducing the data and computation requirements, and creating more robust systems that can generalize across different domains.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  },
  {
    "objectID": "intro.html#perceptron",
    "href": "intro.html#perceptron",
    "title": "1  Basics of Artificial Neural Network",
    "section": "1.2 Perceptron",
    "text": "1.2 Perceptron\nTo continue with the story, a few years after McCulloch and Walter Pitt, Frank Rosenblatt published the first concept of the Perceptron learning rule. The perceptron is one of the earliest neural network models (Rosenblatt 1957).\n\n\n\n\n\n\nFrank Rosenblatt’s Perceptron\n\n\n\nThe main idea was to define an algorithm in order to learn the values of the weights \\(w\\) that are then multiplied with the input features in order to make a decision whether a neuron fires or not. In context of pattern classification, such an algorithm could be useful to determine if a sample belongs to one class or the other.\n\n\nIt models a single artificial neuron capable of binary classification for linearly separable data. Despite its limitations, the perceptron laid the foundation for more complex architectures like Multilayer Perceptrons (MLPs) and deep neural networks, which use sigmoid neurons for non-linear decision boundaries.\n\n1.2.1 Perceptron Model\n\n\n\n\n\ngraph TD\n    X1(Input X1) --&gt; W1(Weight W1)\n    X2(Input X2) --&gt; W2(Weight W2)\n    Xn(Input Xn) --&gt; Wn(Weight Wn)\n    W1 --&gt; SUM[Summation Σ]\n    W2 --&gt; SUM\n    Wn --&gt; SUM\n    B(Bias) --&gt; SUM\n    SUM --&gt; ACT[Activation Function]\n    ACT --&gt; Y(Output Y)\n    \n    style SUM fill:#f9f,stroke:#333,stroke-width:2px\n    style ACT fill:#bbf,stroke:#333,stroke-width:2px\n    style Y fill:#bfb,stroke:#333,stroke-width:2px\n    classDef input fill:#ff9,stroke:#333,stroke-width:2px;\n    classDef weight fill:#9cf,stroke:#333,stroke-width:2px;\n\n    class X1,X2,Xn input;\n    class W1,W2,Wn weight;\n\n\n\n\n\n\nThe perceptron computes a weighted sum of inputs and applies a step function for classification: \\[\nz = \\sum_{i=1}^n w_i x_i + b\n\\] \\[\n\\hat{y} = \\begin{cases}\n      1 & \\text{if } z &gt; 0 \\\\\n      0 & \\text{otherwise}\n   \\end{cases}\n\\]\n\n\n1.2.2 Perceptron Learning Rule\nWeights are updated iteratively based on the error: \\[\nw_i \\gets w_i + \\eta (y - \\hat{y}) x_i\n\\] where \\(\\eta\\) is the learning rate.\n\n\n1.2.3 Perceptron Algorithm\nInput: A dataset \\(D = \\{(x_i, y_i)\\}\\), where \\(x_i\\) is the feature vector and \\(y_i\\in \\{+1,-1\\}\\) is the label.\nOutput: A weight vector \\(\\mathbf{w}\\).\n\nInitialize \\(\\mathbf{w} = \\mathbf{0}\\).\nRepeat until convergence:\n\nSet \\(m = 0\\).\nFor each \\((x_i, y_i) \\in D\\):\n\nIf \\(y_i (\\mathbf{w}^T \\cdot \\mathbf{x_i}) \\leq 0\\):\n\nUpdate \\(\\mathbf{w} \\gets \\mathbf{w} + y_i \\mathbf{x_i}\\).\nIncrement \\(m \\gets m + 1\\).\n\n\nIf \\(m = 0\\), terminate the algorithm.\n\n\n\n\n\n\n\n\nPerceptron Convergence\n\n\n\nThe Perceptron was arguably the first algorithm with a strong formal guarantee. If a data set is linearly separable, the Perceptron will find a separating hyperplane in a finite number of updates. (If the data is not linearly separable, it will loop forever.)\n\n\n\n\n1.2.4 Perceptron Theorem and Margin\nThe Perceptron Mistake Bound Theorem states that the Perceptron algorithm makes at most \\(\\frac{1}{\\gamma^2}\\) updates (mistakes), where \\(\\gamma\\) is the margin of separability of the data. The margin is defined as the smallest distance between any data point and the decision boundary, normalized by the magnitude of the weight vector: \\[\n\\gamma = \\frac{\\min_{i} y_i (\\mathbf{w}^T \\mathbf{x_i})}{\\|\\mathbf{w}\\|}\n\\] where: - \\(\\mathbf{w}\\) is the weight vector. - \\(\\mathbf{x_i}\\) is a data point. - \\(y_i\\) is the corresponding label ((+1) or (-1)).\n\n\n1.2.5 Implications of the Theorem\n\nLarge Margin is Desirable:\n\nA larger margin \\(\\gamma\\) implies fewer mistakes because the mistake bound decreases as \\(\\gamma\\) increases.\nIntuitively, a larger margin means the data points are farther from the decision boundary, making them less likely to be misclassified.\n\nQuick Convergence:\n\nThe algorithm will converge faster on datasets with a larger margin since fewer updates (or mistakes) are required.\nConversely, if \\(\\gamma\\) is small (data points are closer to the boundary), the algorithm requires more updates to separate the data correctly.\n\n\n\n\n1.2.6 Characterizing Data Sets for Fast Convergence\nDatasets for which the Perceptron algorithm converges quickly share the following properties:\n\nLarge Margin:\n\nData points are well-separated from the decision boundary.\nThe decision boundary can be drawn with minimal ambiguity.\n\nLinearly Separable Data:\n\nThe dataset must be linearly separable for the Perceptron algorithm to converge.\nOverlapping or inseparable datasets will cause the algorithm to loop indefinitely.\n\n\n\n\n1.2.7 Example of a Dataset with Large Margin\nConsider the following dataset in two-dimensional space:\n\nPositive class (\\(y_i = +1\\)): Points \\((3, 3), (4, 4), (5, 5)\\).\nNegative class (\\(y_i = -1\\)): Points \\((-3, -3), (-4, -4), (-5, -5)\\).\n\nThe data is linearly separable with a large margin (distance between closest points and the decision boundary).\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Dataset\npositive_points = np.array([[3, 3], [4, 4], [5, 5]])\nnegative_points = np.array([[-3, -3], [-4, -4], [-5, -5]])\n\n# Define weights and bias for the Perceptron hyperplane\n# Example weights (assuming the Perceptron learned these weights)\nw = np.array([1, 1])  # w1 and w2\nb = 0                 # Bias term\n\n# Generate x1 values for plotting\nx1 = np.linspace(-6, 6, 100)\n\n# Compute x2 values from the hyperplane equation w1*x1 + w2*x2 + b = 0\nx2 = -(w[0] * x1 + b) / w[1]\n\n# Plot the dataset\nplt.scatter(positive_points[:, 0], positive_points[:, 1], color='blue', label='Positive Class ($y=+1$)', s=100)\nplt.scatter(negative_points[:, 0], negative_points[:, 1], color='red', label='Negative Class ($y=-1$)', s=100)\n\n# Plot the decision boundary (hyperplane)\nplt.plot(x1, x2, color='black', linestyle='--', label='Decision Boundary ($w^T x = 0$)')\n\n# Formatting the plot\nplt.axhline(0, color='black', linewidth=0.5, linestyle='-')\nplt.axvline(0, color='black', linewidth=0.5, linestyle='-')\nplt.grid(alpha=0.3)\nplt.legend()\nplt.title('Linearly Separable Dataset with Perceptron Decision Boundary')\nplt.xlabel('$x_1$')\nplt.ylabel('$x_2$')\nplt.xlim(-6, 6)\nplt.ylim(-6, 6)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n1.2.8 Visualization of Large vs. Small Margins\nThe following diagrams illustrate the difference between datasets with large and small margins:\n\n\n\n\n\ngraph TD\n    A[Decision Boundary] ---|Large Margin| C((Positive Class))\n    A ---|Large Margin| D((Negative Class))\n    subgraph Large Margin\n        C & D\n    end\n\n    E[Decision Boundary] ---|Small Margin| G((Positive Class))\n    E ---|Small Margin| F((Negative Class))\n    subgraph Small Margin\n        G & F\n    end\n\n\n\n\n\n\n\n\n1.2.9 Simulating OR gate using Perceptron\n\n\n\n\n\n\n\nperceptron\n\n\n\ninput1\n\nx1\n\n\n\nweight1\n\nw1\n\n\n\ninput1-&gt;weight1\n\n\nw1\n\n\n\ninput2\n\nx2\n\n\n\nweight2\n\nw2\n\n\n\ninput2-&gt;weight2\n\n\nw2\n\n\n\nbias\n\nBias (b)\n\n\n\nweighted_sum\n\nw1 * x1 + w2 * x2 + b\n\n\n\nbias-&gt;weighted_sum\n\n\n + b\n\n\n\nweight1-&gt;weighted_sum\n\n\n* x1\n\n\n\nweight2-&gt;weighted_sum\n\n\n* x2\n\n\n\nactivation\n\nActivation Step Function: f(x) = 1 if x &gt;= 0 else 0\n\n\n\nweighted_sum-&gt;activation\n\n\npass to\n\n\n\noutput\n\ny (Output)\n\n\n\nactivation-&gt;output\n\n\nstep function\n\n\n\noutput-&gt;output\n\n\ny\n\n\n\n\n\n\n\n\nThe following python code will simulate the OR gate using the logic of perceptron.\n\nimport numpy as np\n\n# Step function (activation function)\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron training algorithm\ndef perceptron(X, y, learning_rate=0.1, epochs=10):\n    # Initialize weights and bias\n    weights = np.zeros(X.shape[1])\n    bias = 0\n    \n    # Training process\n    for epoch in range(epochs):\n        total_error = 0\n        for i in range(len(X)):\n            # Calculate weighted sum (z)\n            z = np.dot(X[i], weights) + bias\n            # Apply step function to get prediction\n            prediction = step_function(z)\n            \n            # Calculate error\n            error = y[i] - prediction\n            total_error += abs(error)\n            \n            # Update weights and bias based on the error\n            weights += learning_rate * error * X[i]\n            bias += learning_rate * error\n        \n        # Optionally, print the error for each epoch\n        print(f'Epoch {epoch + 1}: Total Error = {total_error}')\n    \n    return weights, bias\n\n# Perceptron test function\ndef predict(X, weights, bias):\n    predictions = []\n    for i in range(len(X)):\n        z = np.dot(X[i], weights) + bias\n        prediction = step_function(z)\n        predictions.append(prediction)\n    return predictions\n\n# OR Gate Inputs and Outputs\n# Input X: [A, B] where A and B are the inputs\n# Output y: The corresponding OR operation output\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([0, 1, 1, 1])  # OR gate outputs\n\n# Train the perceptron\nweights, bias = perceptron(X, y, learning_rate=0.1, epochs=10)\n\n# Test the perceptron\npredictions = predict(X, weights, bias)\n\n# Print predictions\nprint(\"\\nPredictions:\")\nfor i in range(len(X)):\n    print(f'Input: {X[i]}, Predicted Output: {predictions[i]}')\n\nEpoch 1: Total Error = 2\nEpoch 2: Total Error = 2\nEpoch 3: Total Error = 1\nEpoch 4: Total Error = 0\nEpoch 5: Total Error = 0\nEpoch 6: Total Error = 0\nEpoch 7: Total Error = 0\nEpoch 8: Total Error = 0\nEpoch 9: Total Error = 0\nEpoch 10: Total Error = 0\n\nPredictions:\nInput: [0 0], Predicted Output: 0\nInput: [0 1], Predicted Output: 1\nInput: [1 0], Predicted Output: 1\nInput: [1 1], Predicted Output: 1\n\n\n\n\n1.2.10 Simulating AND gate using a perceptron\nThe perceptron model for an AND gate is shown below.\n\n\n\n\n\n\n\nperceptron\n\n\n\ninput1\n\nx1\n\n\n\nweight1\n\nw1\n\n\n\ninput1-&gt;weight1\n\n\nw1\n\n\n\ninput2\n\nx2\n\n\n\nweight2\n\nw2\n\n\n\ninput2-&gt;weight2\n\n\nw2\n\n\n\nbias\n\nBias (b)\n\n\n\nweighted_sum\n\nw1 * x1 + w2 * x2 + b\n\n\n\nbias-&gt;weighted_sum\n\n\n + b\n\n\n\nweight1-&gt;weighted_sum\n\n\n* x1\n\n\n\nweight2-&gt;weighted_sum\n\n\n* x2\n\n\n\nactivation\n\nActivation Step Function: f(x) = 1 if x &gt;= 0 else 0\n\n\n\nweighted_sum-&gt;activation\n\n\npass to\n\n\n\noutput\n\ny (Output)\n\n\n\nactivation-&gt;output\n\n\nstep function\n\n\n\noutput-&gt;output\n\n\ny\n\n\n\n\n\n\n\n\nThe python code for simulating the AND gate using the perceptron is shown below.\n\nimport numpy as np\n\n# Step function (activation function)\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron training algorithm\ndef perceptron(X, y, learning_rate=0.1, epochs=10):\n    # Initialize weights and bias\n    weights = np.zeros(X.shape[1])\n    bias = 0\n    \n    # Training process\n    for epoch in range(epochs):\n        total_error = 0\n        for i in range(len(X)):\n            # Calculate weighted sum (z)\n            z = np.dot(X[i], weights) + bias\n            # Apply step function to get prediction\n            prediction = step_function(z)\n            \n            # Calculate error\n            error = y[i] - prediction\n            total_error += abs(error)\n            \n            # Update weights and bias based on the error\n            weights += learning_rate * error * X[i]\n            bias += learning_rate * error\n        \n        # Optionally, print the error for each epoch\n        print(f'Epoch {epoch + 1}: Total Error = {total_error}')\n    \n    return weights, bias\n\n# Perceptron test function\ndef predict(X, weights, bias):\n    predictions = []\n    for i in range(len(X)):\n        z = np.dot(X[i], weights) + bias\n        prediction = step_function(z)\n        predictions.append(prediction)\n    return predictions\n\n# OR Gate Inputs and Outputs\n# Input X: [A, B] where A and B are the inputs\n# Output y: The corresponding OR operation output\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([0, 1, 1, 1])  # OR gate outputs\n\n# Train the perceptron\nweights, bias = perceptron(X, y, learning_rate=0.1, epochs=10)\n\n# Test the perceptron\npredictions = predict(X, weights, bias)\n\n# Print predictions\nprint(\"\\nPredictions:\")\nfor i in range(len(X)):\n    print(f'Input: {X[i]}, Predicted Output: {predictions[i]}')\n\nEpoch 1: Total Error = 2\nEpoch 2: Total Error = 2\nEpoch 3: Total Error = 1\nEpoch 4: Total Error = 0\nEpoch 5: Total Error = 0\nEpoch 6: Total Error = 0\nEpoch 7: Total Error = 0\nEpoch 8: Total Error = 0\nEpoch 9: Total Error = 0\nEpoch 10: Total Error = 0\n\nPredictions:\nInput: [0 0], Predicted Output: 0\nInput: [0 1], Predicted Output: 1\nInput: [1 0], Predicted Output: 1\nInput: [1 1], Predicted Output: 1\n\n\n\n\n1.2.11 Simulating NOR gate using the Perceptron\nHere is the Python code to simulate a perceptron for a NOR gate. The NOR gate is the negation of the OR gate, so it outputs 1 only when both inputs are 0.\n\nimport numpy as np\n\n# Define the step function\ndef step_function(x):\n    return 1 if x &gt;= 0 else 0\n\n# Perceptron class to simulate the NOR gate\nclass Perceptron:\n    def __init__(self, input_size, learning_rate=0.1):\n        # Initialize weights and bias to zero\n        self.weights = np.zeros(input_size)\n        self.bias = 0\n        self.learning_rate = learning_rate\n\n    def predict(self, inputs):\n        # Calculate the weighted sum\n        weighted_sum = np.dot(inputs, self.weights) + self.bias\n        # Apply the step activation function\n        return step_function(weighted_sum)\n\n    def train(self, inputs, targets, epochs=10):\n        # Train the perceptron using the input-output pairs\n        for epoch in range(epochs):\n            for i in range(len(inputs)):\n                input_data = inputs[i]\n                target = targets[i]\n                # Compute the prediction\n                prediction = self.predict(input_data)\n                # Calculate the error\n                error = target - prediction\n                # Update the weights and bias using the perceptron learning rule\n                self.weights += self.learning_rate * error * input_data\n                self.bias += self.learning_rate * error\n\n# Define the input-output pairs for a NOR gate\ninputs = np.array([\n    [0, 0],  # Input: (0, 0)\n    [0, 1],  # Input: (0, 1)\n    [1, 0],  # Input: (1, 0)\n    [1, 1],  # Input: (1, 1)\n])\n\n# Output of NOR gate\ntargets = np.array([1, 0, 0, 0])\n\n# Create and train the perceptron\nperceptron = Perceptron(input_size=2)\nperceptron.train(inputs, targets, epochs=10)\n\n# Test the trained perceptron on the inputs\nprint(\"Trained weights:\", perceptron.weights)\nprint(\"Trained bias:\", perceptron.bias)\n\n# Test the perceptron for all input combinations\nfor input_data in inputs:\n    prediction = perceptron.predict(input_data)\n    print(f\"Input: {input_data}, Prediction: {prediction}\")\n\nTrained weights: [-0.1 -0.1]\nTrained bias: 0.0\nInput: [0 0], Prediction: 1\nInput: [0 1], Prediction: 0\nInput: [1 0], Prediction: 0\nInput: [1 1], Prediction: 0\n\n\nThis code will train the perceptron to simulate the NOR gate and test it for all possible input combinations. The weights and bias will be adjusted during training to ensure the perceptron correctly implements the NOR gate behavior.\n\n\n1.2.12 Perceptron fails!\nwhether the perceptron win on XOR gate? No, the perceptron cannot learn the XOR gate. This is a well-known limitation of the perceptron model, and it’s related to the fact that the XOR function is non-linearly separable.\n\n\n\n\n\n\nPerceptron fails!\n\n\n\nA perceptron can only solve problems that are linearly separable, meaning that the classes (outputs) can be separated by a straight line (or a hyperplane in higher dimensions). The XOR gate outputs 1 when the inputs are (0, 1) or (1, 0), and outputs 0 when the inputs are (0, 0) or (1, 1).\nIf you try to plot these points, you’ll see that you can’t separate the positive examples (output 1) from the negative examples (output 0) with a single straight line.\n\n\n\n\n1.2.13 Perceptron neuron- the foundation of modern Machine Learning\nThe Perceptron model, introduced by Frank Rosenblatt in 1958, marked one of the earliest developments in artificial intelligence and neural networks. Initially conceived as a model for pattern recognition and early neural computation, the Perceptron was designed to simulate a biological neuron, learning to classify inputs into two categories through a simple linear decision boundary. Despite its early promise, the limitations of the basic Perceptron were exposed in the 1960s, particularly its inability to solve non-linearly separable problems, famously highlighted in Marvin Minsky and Seymour Papert’s book Perceptrons (1969). However, with the advent of more sophisticated algorithms and architectures, such as multi-layer perceptrons (MLPs) and the backpropagation algorithm in the 1980s, the Perceptron concept was revitalized. Today, it forms the foundational concept for deep learning models and modern neural networks, which are widely applied in various fields, including image and speech recognition, natural language processing, and autonomous systems, demonstrating its enduring relevance and adaptability in tackling complex, non-linear real-world problems.\n\n\n\n1.2.14 Introduction to the Sigmoid Activation Function\nThe sigmoid function, defined as\n\\[\n\\sigma(x) = \\frac{1}{1 + e^{-x}},\n\\]\nmaps any real-valued input to an output between 0 and 1, making it ideal for binary classification tasks. It has played a pivotal role in the development of neural networks, especially in overcoming the limitations of the step function used in early perceptrons.\n\n\n1.2.15 Historical Context\nIn the 1950s, Frank Rosenblatt’s perceptron used the step function, which works well for linearly separable problems but fails with more complex datasets, like the XOR problem. The introduction of the sigmoid activation function in the 1980s addressed this by enabling smooth decision boundaries and facilitating the backpropagation algorithm, allowing neural networks to learn from data effectively.\n\n\n1.2.16 Relevance to Modern Neural Networks\nThe sigmoid function’s differentiability makes it ideal for gradient-based optimization, which is essential for training deep neural networks. Its output is a probability, making it suitable for binary classification problems. Additionally, the derivative of the sigmoid is easy to compute:\n\\[\n\\sigma'(x) = \\sigma(x)(1 - \\sigma(x)),\n\\]\nwhich aids in backpropagation by allowing efficient weight updates. Despite some limitations, such as the vanishing gradient problem, the sigmoid function is widely used in the output layers of networks for tasks requiring probabilistic outputs.\n\n\n1.2.17 Applications\n\nBinary classification (e.g., logistic regression).\nOutput layer in neural networks for binary classification.\nProbabilistic models in machine learning and AI.\n\nWhile alternatives like ReLU are often used in deeper layers due to the vanishing gradient problem, sigmoid remains a powerful tool for probabilistic predictions.\n\n\n1.2.18 Sigmoid Neuron\nThe sigmoid neuron replaces the step function with the sigmoid function: \\[\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\] This allows for smooth gradients, enabling the use of backpropagation for training MLPs.\n\n\n\n\n\n\n\nNeuralNetwork\n\n\ncluster_input\n\nInput Layer\n\n\ncluster_neuron\n\nSigmoid Neuron\n\n\ncluster_weights\n\nWeights\n\n\ncluster_output\n\nOutput Layer\n\n\n\nX1\n\nx1\n\n\n\nW1\n\nw1\n\n\n\nX1-&gt;W1\n\n\n\n\n\nX2\n\nx2\n\n\n\nW2\n\nw2\n\n\n\nX2-&gt;W2\n\n\n\n\n\nXn\n\nxn\n\n\n\nWn\n\nwn\n\n\n\nXn-&gt;Wn\n\n\n\n\n\nSUM\n\nΣ = Σ(wi * xi) + b\n\n\n\nW1-&gt;SUM\n\n\n\n\n\nW2-&gt;SUM\n\n\n\n\n\nWn-&gt;SUM\n\n\n\n\n\nSIGMOID\n\nσ(z) = 1 / (1 + exp(-z))\n\n\n\nSUM-&gt;SIGMOID\n\n\n\n\n\nY\n\ny\n\n\n\nSIGMOID-&gt;Y\n\n\n\n\n\nB\n\nb (Bias)\n\n\n\nB-&gt;SUM\n\n\n\n\n\n\n\n\n\n\nFollowing python code demonstrate the effective use of the sigmoid activation function in the simulation of an AND gate.\n\nimport numpy as np\n\n# Sigmoid activation function\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# Derivative of sigmoid for gradient calculation\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\n# Define the training inputs and outputs (AND gate)\nX = np.array([[0, 0],\n              [0, 1],\n              [1, 0],\n              [1, 1]])\n\ny = np.array([[0], [0], [0], [1]])  # Expected output for AND gate\n\n# Initialize weights and bias randomly\nweights = np.random.rand(2, 1)  # Random weights for 2 inputs\nbias = np.random.rand(1)  # Random bias\n\n# Learning rate\nlearning_rate = 0.1\n\n# Training the perceptron\nfor epoch in range(10000):  # Number of iterations\n    # Forward pass\n    weighted_sum = np.dot(X, weights) + bias\n    output = sigmoid(weighted_sum)\n\n    # Compute error\n    error = y - output\n    \n    # Backpropagation (Gradient Descent)\n    adjustment = error * sigmoid_derivative(output)\n    weights += np.dot(X.T, adjustment) * learning_rate\n    bias += np.sum(adjustment) * learning_rate\n\n    # Optional: Print the error at intervals\n    if epoch % 1000 == 0:\n        print(f\"Epoch {epoch}, Error: {np.mean(np.abs(error))}\")\n\n# Testing the perceptron\nprint(\"\\nFinal Output After Training:\")\nfor i in range(len(X)):\n    print(f\"Input: {X[i]} =&gt; Predicted Output: {round(output[i][0])}\")\n\nEpoch 0, Error: 0.5619616767302489\nEpoch 1000, Error: 0.15711929476169195\nEpoch 2000, Error: 0.10888895642561364\nEpoch 3000, Error: 0.08691945516104863\nEpoch 4000, Error: 0.07396708090435249\nEpoch 5000, Error: 0.06526595419809272\nEpoch 6000, Error: 0.05893908456310959\nEpoch 7000, Error: 0.05408757038030876\nEpoch 8000, Error: 0.05022291881319084\nEpoch 9000, Error: 0.047054971144594046\n\nFinal Output After Training:\nInput: [0 0] =&gt; Predicted Output: 0\nInput: [0 1] =&gt; Predicted Output: 0\nInput: [1 0] =&gt; Predicted Output: 0\nInput: [1 1] =&gt; Predicted Output: 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of Artificial Neural Network</span>"
    ]
  }
]